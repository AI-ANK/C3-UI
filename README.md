# C3 Voice Assistant: Accessible LLM Frontend for Everyone

Welcome to the C3 Voice Assistant, a cutting-edge frontend module designed for ease of use and accessibility. This project emphasizes making Large Language Models (LLMs) accessible to all, including those with limitations in typing or other accessibility challenges.

## Demo Features
- **Voice Activation**: Just say "C3" to activate the assistant.
- **General Queries**: Ask any question as you would with a standard LLM.
- **Document-Based Responses (RAG)**: Get answers related to specific documents. Currently supports queries about Nvidia's FYE 2023 10K report.
- **Accessibility Focused**: Ideal for users requiring voice-based interaction.
- **Vercel Deployment**: Check out the production version on Vercel.

## Tools and Technologies
- **Frontend**: Custom-built React.js application.
- **LLM Backend**: Python Flask, leveraging LlamaIndex's 'Create Llama' feature.
- **Hosting**: API server on Render.com and frontend on Vercel.

## Project Structure
- `/src`: Source files for the frontend application.
- `/api`: Python Flask backend for processing LLM queries.

## Setup and Usage
- Frontend: Deployed on Vercel, accessible directly.
- Backend: Python Flask app, deployable via Render.com.

## Feedback and Contributions
Your insights and contributions are welcome. Feel free to raise issues or submit pull requests for enhancements.

## Acknowledgements
Developed by Harshad Suryawanshi. If you find this project helpful, consider giving it a ‚≠ê on GitHub!

[View the Live Demo](#)
